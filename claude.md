# Claude Rules

---

## ğŸš¨ CRITICAL AI USAGE RULES - ì ˆëŒ€ ìœ„ë°˜ ê¸ˆì§€

> **ì´ ê·œì¹™ì€ ëª¨ë“  ìƒí™©ì—ì„œ ë°˜ë“œì‹œ ì§€ì¼œì•¼ í•©ë‹ˆë‹¤. ì˜ˆì™¸ ì—†ìŒ.**

### 1. ì´ë¯¸ì§€/ë™ì˜ìƒ AI â†’ Vertex AI í•„ìˆ˜

```
ğŸ”´ ì´ë¯¸ì§€ ìƒì„±, ì´ë¯¸ì§€ ë¶„ì„, ë™ì˜ìƒ ìƒì„±/ë¶„ì„ = Vertex AI ONLY
```

- **í•„ìˆ˜ ì‚¬ìš©**: `@google-cloud/vertexai` íŒ¨í‚¤ì§€
- **í•„ìˆ˜ ì¸ì¦**: GCP ì„œë¹„ìŠ¤ ê³„ì • (JSON í‚¤ íŒŒì¼)
- **ê¸ˆì§€**: `@google/genai` íŒ¨í‚¤ì§€ë¡œ ì´ë¯¸ì§€/ë™ì˜ìƒ ì²˜ë¦¬

```typescript
// âœ… ì˜¬ë°”ë¥¸ ë°©ë²•: Vertex AI for Image/Video
import { VertexAI } from '@google-cloud/vertexai';

const vertexAI = new VertexAI({
  project: process.env.GCP_PROJECT_ID,
  location: process.env.GCP_LOCATION,
});
```

```typescript
// âŒ ê¸ˆì§€: ì´ë¯¸ì§€/ë™ì˜ìƒì— Google AI Studio API ì‚¬ìš©
import { GoogleGenAI } from '@google/genai';
const ai = new GoogleGenAI({ apiKey: process.env.GOOGLE_AI_API_KEY });
// ì´ë¯¸ì§€/ë™ì˜ìƒ ì²˜ë¦¬ ê¸ˆì§€!
```

### 2. LLM (í…ìŠ¤íŠ¸) AI â†’ GOOGLE_AI_API_KEY í•„ìˆ˜

```
ğŸ”´ í…ìŠ¤íŠ¸ ìƒì„±, í…ìŠ¤íŠ¸ ë¶„ì„ = GOOGLE_AI_API_KEY ONLY
```

- **í•„ìˆ˜ ì‚¬ìš©**: `@google/genai` íŒ¨í‚¤ì§€
- **í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜**: `GOOGLE_AI_API_KEY`
- **ê¸ˆì§€**: Vertex AIë¡œ ì¼ë°˜ í…ìŠ¤íŠ¸ LLM ì²˜ë¦¬

```typescript
// âœ… ì˜¬ë°”ë¥¸ ë°©ë²•: Google AI Studio for LLM
import { GoogleGenAI } from '@google/genai';

const ai = new GoogleGenAI({
  apiKey: process.env.GOOGLE_AI_API_KEY, // ë°˜ë“œì‹œ ì´ í‚¤ ì‚¬ìš©!
});
```

### ìš”ì•½ í‘œ

| ì‘ì—… ìœ í˜• | ì‚¬ìš©í•  ì„œë¹„ìŠ¤ | íŒ¨í‚¤ì§€ | API í‚¤/ì¸ì¦ |
|----------|-------------|--------|------------|
| ì´ë¯¸ì§€ ìƒì„± | Vertex AI | `@google-cloud/vertexai` | GCP ì„œë¹„ìŠ¤ ê³„ì • |
| ì´ë¯¸ì§€ ë¶„ì„ | Vertex AI | `@google-cloud/vertexai` | GCP ì„œë¹„ìŠ¤ ê³„ì • |
| ë™ì˜ìƒ ìƒì„±/ë¶„ì„ | Vertex AI | `@google-cloud/vertexai` | GCP ì„œë¹„ìŠ¤ ê³„ì • |
| í…ìŠ¤íŠ¸ ìƒì„± (LLM) | Google AI Studio | `@google/genai` | `GOOGLE_AI_API_KEY` |
| í…ìŠ¤íŠ¸ ë¶„ì„ (LLM) | Google AI Studio | `@google/genai` | `GOOGLE_AI_API_KEY` |

---

## Response Style

- ALWAYS think through problems step-by-step before providing answers
- Break down complex tasks into smaller, manageable steps
- Explain your reasoning process clearly at each stage

## General Restrictions

- Do NOT run `npm run dev` or `npm run build` without explicit user permission
- Do NOT create README or markdown files unless explicitly told to
- Do NOT change AI models (e.g., Gemini model versions) without explicit user permission
- Use only muted colors like black, grey, and white. Never use colors unless explicitly told to for design.

## Database Operations

- ALWAYS use Supabase MCP tools (`mcp__supabase__*`) for database migrations and schema lookups instead of raw SQL files or Drizzle CLI

## Documentation

- ALWAYS check with Context7 MCP tool (`mcp__context7__*`) for library documentation before implementing code

---

## AI Integration - MUST USE AGENT SYSTEM

**CRITICAL**: All AI usage in this project MUST go through the Agent System at `lib/agents/`.
Do NOT use direct AI API calls outside of the agent system.

### Why Agent System?

- Centralized prompt management (database-driven prompts)
- Execution logging and metrics tracking
- Input/output validation with Zod schemas
- Model client abstraction (Gemini/OpenAI)
- Consistent error handling

### Agent System Architecture (`lib/agents/`)

```
lib/agents/
â”œâ”€â”€ base-agent.ts      # Abstract base class for all agents
â”œâ”€â”€ types.ts           # Type definitions
â”œâ”€â”€ orchestrator.ts    # Workflow orchestrator
â”œâ”€â”€ prompt-loader.ts   # Database prompt loading
â”œâ”€â”€ evaluation-service.ts # Execution logging
â”œâ”€â”€ analyzers/         # Vision, Text Pattern, Visual Trend, Strategy
â”œâ”€â”€ creators/          # Creative Director, Script Writer
â”œâ”€â”€ transformers/      # Prompt Engineer, I2V Specialist
â”œâ”€â”€ publishers/        # Publish Optimizer, Copywriter
â””â”€â”€ compose/           # Compose-specific agents
```

### Model Assignments

- **Gemini 2.5 Flash**: Analyzers, Transformers (fast analysis) - via `GOOGLE_AI_API_KEY`
- **Gemini 3 Pro**: Creative Director (deep reasoning) - via `GOOGLE_AI_API_KEY`
- **Vertex AI**: Image/Video generation and analysis - via GCP ì„œë¹„ìŠ¤ ê³„ì •
- **GPT-5.1**: Publishers (copywriting)

### How to Add New AI Functionality

1. **Create a new agent** extending `BaseAgent`:

```typescript
import { BaseAgent } from '@/lib/agents/base-agent';
import { z } from 'zod';
import type { AgentContext } from '@/lib/agents/types';

export const MyAgentInputSchema = z.object({ /* your fields */ });
export const MyAgentOutputSchema = z.object({ /* your fields */ });
export type MyAgentInput = z.infer<typeof MyAgentInputSchema>;
export type MyAgentOutput = z.infer<typeof MyAgentOutputSchema>;

export class MyAgent extends BaseAgent<MyAgentInput, MyAgentOutput> {
  constructor() {
    super({
      id: 'my-agent',
      name: 'My Agent',
      description: 'Agent description',
      category: 'analyzer',
      model: {
        provider: 'gemini',
        name: 'gemini-2.5-flash',
        options: { temperature: 0.7 }
      },
      prompts: {
        system: 'Your system prompt...',
        templates: {}
      },
      inputSchema: MyAgentInputSchema,
      outputSchema: MyAgentOutputSchema,
    });
  }

  protected buildPrompt(input: MyAgentInput, context: AgentContext): string {
    return `Your prompt with ${JSON.stringify(input)}`;
  }
}
```

2. **Use the agent**:

```typescript
import { createMyAgent } from '@/lib/agents/my-agent';

const agent = createMyAgent();
const result = await agent.execute(input, context);

if (result.success) {
  console.log(result.data);
} else {
  console.error(result.error);
}
```

### FORBIDDEN - Do NOT do this:

```typescript
// âŒ WRONG: Direct API calls outside agent system
import { GoogleGenAI } from '@google/genai';
const ai = new GoogleGenAI({ apiKey: process.env.GOOGLE_AI_API_KEY });
const response = await ai.models.generateContent(...);

// âŒ WRONG: Using Google AI API for image/video (must use Vertex AI)
import { GoogleGenAI } from '@google/genai';
const ai = new GoogleGenAI({ apiKey: process.env.GOOGLE_AI_API_KEY });
// ì´ë¯¸ì§€/ë™ì˜ìƒ ì²˜ë¦¬ ê¸ˆì§€!

// âŒ WRONG: Using Vertex AI for text LLM (must use GOOGLE_AI_API_KEY)
import { VertexAI } from '@google-cloud/vertexai';
const vertexAI = new VertexAI({ project, location });
const model = vertexAI.getGenerativeModel({ model: 'gemini-pro' });
await model.generateContent('text prompt'); // LLMì€ ê¸ˆì§€!
```

### Model Clients (internal use in Agent System only)

- `GeminiClient` - for LLM text generation (uses `GOOGLE_AI_API_KEY`)
- `VertexAIClient` - for image/video generation and analysis (uses GCP ì„œë¹„ìŠ¤ ê³„ì •)

---

## Environment Variables

```bash
# LLM (í…ìŠ¤íŠ¸) - Google AI Studio
GOOGLE_AI_API_KEY=your-google-ai-api-key

# Image/Video - Vertex AI
GCP_PROJECT_ID=your-gcp-project-id
GCP_LOCATION=us-central1
GOOGLE_APPLICATION_CREDENTIALS=./path-to-service-account.json
```
